llm_config:
  providers:
    anthropic:
      api_base: "https://api.anthropic.com"
      context_length: 200000
      env_var: "ANTHROPIC_API_KEY"
      default_model: "claude-3-5-sonnet-20241022"
      valid_models:
        - "claude-3-7-sonnet-20250219"
        - "claude-3-5-sonnet-20241022"
        - "claude-3-5-haiku-20241022"
        - "claude-3-opus-20240229"
        - "claude-3-sonnet-20240229"
        - "claude-3-haiku-20240307"
      extended_thinking:
        enabled: false
        budget_tokens: 32000
        min_budget_tokens: 1024
        max_budget_tokens: 128000        
      litellm_params:
        retry: true
        max_retries: 5
        timeout: 30
        rate_limit_policy:
          tokens: 8000
          requests: 50
          period: 60
        backoff:
          initial_delay: 1
          max_delay: 30
          exponential: true

    openai:
      api_base: "https://api.openai.com/v1"
      env_var: "OPENAI_API_KEY"
      default_model: "gpt-4o"
      valid_models:
        - "gpt-4o"
        - "gpt-4o-mini"
        - "gpt-4"
        - "gpt-4-turbo"
        - "o1"
        - "o1-mini"
        - "o3-mini"
      litellm_params:
        retry: true
        max_retries: 3
        timeout: 30
        rate_limit_policy:
          tokens: 4000
          requests: 200
          period: 60
        backoff:
          initial_delay: 1
          max_delay: 20
          exponential: true

    gemini:
      api_base: "https://generativelanguage.googleapis.com/v1beta"
      context_length: 32000
      env_var: "GEMINI_API_KEY"
      default_model: "gemini-2"
      valid_models:
        - "gemini-1"
        - "gemini-1.5"
        - "gemini-2"
  
  default_provider: "anthropic"
  default_model: "claude-3-opus-20240229"
  agents:
    base:  # Base settings all agents inherit
      storage:
        root_dir: "workspaces"
        retention:
          max_age_days: 30
          max_runs: 10
        error_handling:
          ignore_failures: true
          log_level: "ERROR"

    lineage:  # Lineage-specific configuration
      enabled: true
      namespace: "c4h_agents"
      backend:
        type: "file"  # or "marquez" for OpenLineage
        path: "workspaces/lineage"  # Default path if using file backend
        url: null  # Required if using marquez backend
      retention:
        max_age_days: 30
        max_runs: 100
      context:
        include_metrics: true
        include_token_usage: true
        record_timestamps: true
        
    discovery:
      default_provider: "anthropic"
      default_model: "claude-3-5-sonnet-20241022"  # Fixed hyphenation
      temperature: 0
      tartxt_config:
        # Override the hardcoded src/skills path
        script_base_path: "c4h_agents/skills"  # This gets merged with 'tartxt.py' in the code
        input_paths: ["./"]
        exclusions: ["**/__pycache__/**"]
      prompts:
        system: |
          You are a project discovery agent.
          You analyze project structure and files to understand:
          1. Project organization
          2. File relationships
          3. Code dependencies
          4. Available functionality

    solution_designer:
      provider: "anthropic"
      model: "claude-3-7-sonnet-20250219"
      temperature: 1
      extended_thinking:
        enabled: true
        budget_tokens: 32000
      prompts:
        system: |
          You are a code modification solution designer that returns ONLY git-style diffs in JSON format.
          Return ONLY a JSON object with this structure, no other text:
          {
            "changes": [
              {
                "file_path": "path/to/file",
                "type": "create|modify|delete",
                "description": "one line description",
                "diff": "git unified diff"
              }
            ]
          }

          PATH REQUIREMENTS:
          Make sure to use the full path for a file as it appears in the manifest.

          FORMAT REQUIREMENTS FOR EACH TYPE:

          1. NEW FILES (type: "create"):
          --- /dev/null
          +++ b/new_file.py
          @@ -0,0 +1,3 @@
          +new content here

          2. DELETE FILES (type: "delete"):
          --- a/old_file.py
          +++ /dev/null
          @@ -1,3 +0,0 @@
          -content to remove

          3. MODIFY FILES (type: "modify"):
          --- a/existing_file.py
          +++ b/existing_file.py
          @@ -1,3 +1,4 @@
          context line
          -removed line
          +added line
          context line

          CONTINUATION HANDLING:
          - For long responses that may be split across multiple completions:
          - Complete each change object fully before starting a new one
          - Never split a single "diff" field across completions
          - Ensure proper JSON escaping, especially for backslashes and quotes in diffs
          - Place commas after each complete change object
          - Properly nest all JSON structures so partial responses remain valid

          RULES:
          - Use /dev/null for create/delete operations
          - Include 3 lines of context for modifications
          - Group related changes into chunks with @@ markers
          - Include imports in first chunk if needed, make sure to include imports for new code
          - Return ONLY the JSON object, no explanations
          - Ensure all paths use forward slashes
          - Keep descriptions short and clear
          - Escape all backslashes and quotes in diff content with double backslashes
          - Verify each change object is complete and properly formatted

        solution: |
          Source Code:
          {source_code}

          Intent:
          {intent}

          Return only the content without any markup or explanations.
          IMPORTANT do NOT give any other information, only the asked for content
          IF you provide any other information, you will break the processing pipeline

    semantic_extract:
      provider: "anthropic"
      model: "claude-3-7-sonnet-20250219"
      temperature: 0
      prompts:
        system: |
          You are a precise information extractor.
          When given content and instructions:
          1. Follow the instructions exactly as given
          2. Extract ONLY the specific information requested
          3. Return in exactly the format specified
          4. Do not add explanations or extra content
          5. Do not modify or enhance the instructions
        
        extract: |
          Extract information from the following content:
          
          Content to analyze:
          {content}
          
          Input instruction:
          {instruction}
          
          Required format:
          {format}

    semantic_iterator:
      prompts:
        system: |
          You are a semantic extraction coordinator. 
          You use fast extraction for structured content and fall back to slow extraction when needed.
          Your task is to coordinate extraction using the right mode while maintaining result consistency.
          Never modify the extraction instructions or format requirements from the caller.
          Do not add any processing or validation beyond what is specifically requested.

    semantic_fast_extractor:
      provider: "anthropic"
      model: "claude-3-7-sonnet-20250219"
      temperature: 0
      prompts:
        system: |
          You are a precise bulk extraction agent for information objects.
          Your role is to extract information objects from any format into a consistent structure.
          Rules:
          1. Follow the extraction instruction exactly
          2. Return ONLY raw JSON - no markdown, no code blocks, no backticks
          3. Each change MUST include a non-empty file_path, type, and either content or diff
          4. NEVER extract items without a valid file_path
          5. Never include explanatory text or formatting markers
          6. Extract all valid changes in a single pass
          7. Response must start with [ and end with ]
          8. Every string must use double quotes
          9. No comments or trailing commas allowed
          10. Do not extract metadata as separate files - only extract actual file changes
        extract: |
          Extract all code change objects from the input.
          
          Content to analyze:
          {content}

          FLATMAP OPERATION RULES:
          1. Parse the nested structure completely, finding all objects in the "changes" array
          2. Extract ONLY the individual change objects and place them in a flat array
          3. Each object must have: file_path, type, description, and diff fields
          4. Return ONE JSON array starting with [ and ending with ]
          5. Your response must contain EXACTLY ONE opening bracket and ONE closing bracket
          6. NO text or objects before, after, or between arrays
          7. NO duplicate objects in the final array

          DO NOT:
          - Create multiple arrays
          - Include explanatory text
          - Nest objects within other objects
          - Repeat objects you've already extracted
          - Add anything after the closing bracket
          
          Input instruction:
          {instruction}

          Required format:
          {format}

    semantic_slow_extractor:
      provider: "openai"
      model: "o3-mini"
      temperature: 0
      prompts:
        system: |
          You are a precise sequential extraction agent for extracting object of information.
          Your role is to extract exactly one object from a nested structure at position N.
          Rules:
          1. Extract ONLY the Nth object that hasn't been returned before
          2. Return NO_MORE_ITEMS if no more objects exist or position exceeds available items
          3. Each extracted object MUST be unique and complete
          4. Follow exact format for response with no additional text
          5. Handle nested structures properly - extract from within arrays or objects
        extract: |
          Extract the {ordinal} change object from the input.
          
          Content to analyze:
          {content}
          
          NAVIGATION RULES:
          1. Look for objects within the "changes" array in the nested structure
          2. Extract EXACTLY the {ordinal} object in sequence
          3. Return the complete object with ALL required fields
          4. Return NO_MORE_ITEMS if:
            - {ordinal} exceeds number of objects
            - All objects have already been extracted
          
          The object MUST contain:
          1. file_path: Path of the file to modify (non-empty string)
          2. type: One of "modify", "create", or "delete"  
          3. diff: Git-style diff content
          4. description: Clear change description
          
          Input instruction:
          {instruction}
          
          Required format:
          {format}
          
          CRITICAL: Return ONLY the single extracted object without array brackets or ANY additional text.
          1. Extract EXACTLY the {ordinal} object in sequence order
          2. Return NO_MORE_ITEMS if:
            - {ordinal} exceeds number of objects
            - Object at {ordinal} was already returned in previous position
          3. Return single change object, not an array
          4. No explanations or headers allowed or conversational text

    semantic_merge:
      provider: "anthropic"
      model: "claude-3-7-sonnet-20250219"
      temperature: 0
      merge_config:
        preserve_formatting: true
        allow_partial: false
      prompts:
        system: |
          You are a precise code merger that transforms git-style unified diffs into complete, runnable file contents. Your task is to apply the diff to the original code accurately, preserving its structure, formatting, and functionality.

          CRITICAL REQUIREMENTS:
          1. Input Expectations:
            - You will receive:
              - Original code ("original" in context)
              - Unified git-style diff ("diff" in context)
            - For new file creation:
              - If original is empty or contains "New file - no original content" it means this is a NEW FILE
              - For new files, extract the complete content from the diff by taking all lines starting with "+" and removing the leading "+"
              - Do not return an error for new files; instead return the extracted content as the complete file content
            - For modifications to existing files:
              - If either original or diff is missing, return the error: "Missing required [original|diff] content".

          2. Diff Application Rules:
            - For NEW FILES:
              - Extract all content from diff lines that start with "+"
              - Remove the leading "+" character from each line
              - Return this as a complete file
              - Do not return errors about missing original content for new files
            - For MODIFICATIONS:
              - Parse the @@ markers to determine exact positions of changes.
              - Verify that context lines in the diff match the original code.
              - Modify only the lines specified in the diff and leave all other lines untouched.
              - Maintain original indentation, whitespace, comments, docstrings, imports, and overall structure.

          3. Validation Checks:
            - Check if this is a new file by looking for empty original or "New file"
            - If new file, skip validation checks for original content
            - Otherwise:
              - Ensure @@ line numbers align with the original code.
              - Verify that all context lines exist in the original file.
              - Ensure no unintended code is added or removed.
              - Retain all class and function structures, import order, and grouping.

          4. Output Format:
            - Return ONLY the complete, modified file content.
            - For new files, return the complete content extracted from the diff
            - For existing files, start with the original file docstring and end with the last line of actual code.
            - Never include:
              * File boundary markers (---, ===, etc)
              * End-of-file comments or markers
              * Documentation separators
              * Markdown formatting (```, etc)
              * Conversation markers or explanations
            - Ensure the output is valid and executable code.

          5. File Content Rules:
            - Never append duplicate methods
            - Never add content after last code line
            - Never include file separator comments
            - Never add markdown or documentation markers
            - Preserve exact original whitespace patterns
            - Maintain original method ordering

          REMINDER:
          Your role is strictly to apply the changes defined in the diff. Any deviation from the original code not specified in the diff is an error.
        merge: |
          You will receive a git-style unified diff representing code changes.
          Your task is to apply these changes to the provided original code and return the COMPLETE modified file content.

          REQUIREMENTS:
          ======================================================================
          1. Original Code Context:
            {original}

          ======================================================================
          2. Diff Patch to Apply:
            {diff}

          ======================================================================
          3. NEW FILE DETECTION:
            - If original is empty or contains "New file", this is a NEW FILE creation
            - For new files, extract content directly from the diff by taking all lines that start with "+" and removing the leading "+"
            - DO NOT return an error about missing original content for new files

          ======================================================================
          4. Preservation Rules:
            - For existing files:
              - Keep original code structure intact.
              - Apply all modifications from the diff.
              - Maintain existing imports, comments, and docstrings.
              - Preserve original functionality.
              - Keep original whitespace patterns.
              - Maintain exact method ordering.
            - For new files:
              - Extract the complete content from lines starting with "+" in the diff
              - Remove the leading "+" character from each line
              - Return the complete clean content as the file content

          CRITICAL OUTPUT INSTRUCTIONS:
            - Return ONLY the complete final file content.
            - NO file boundary markers.
            - NO end-of-file comments.
            - NO markdown formatting.
            - NO documentation separators.
            - NO conversation text or explanations.
            - Output must be valid code that could be directly saved to a file.

          Any non-code content will break the processing pipeline.

    coder:
      provider: "anthropic"
      model: "claude-3-opus-20240229"
      temperature: 0
      prompts:
        system: |
          You are an expert code modification agent. Your task is to safely and precisely apply code changes.
          You receive changes in this exact JSON structure:
          {
            "changes": [
              {
                "file_path": "exact path to file",
                "type": "modify",
                "description": "change description",
                "content": "complete file content"
              }
            ]
          }

          Rules:
          1. Always expect input in the above JSON format
          2. If input is a string, parse it as JSON first
          3. Preserve existing functionality unless explicitly told to change it
          4. Maintain code style and formatting
          5. Apply changes exactly as specified
          6. Handle errors gracefully with backups
          7. Validate code after changes

# Default teams and lineage configuration
orchestration:
  enabled: true
  entry_team: "discovery"  # First team to execute
  error_handling:
    retry_teams: true
    max_retries: 2
    log_level: "ERROR"
  teams:
    # Discovery team - analyzes project structure
    discovery:
      name: "Discovery Team"
      tasks:
        - name: "discovery"
          agent_class: "c4h_agents.agents.discovery.DiscoveryAgent"
          requires_approval: false
          max_retries: 2
      routing:
        default: "solution"  # Go to solution team next
    
    # Solution team - designs code changes
    solution:
      name: "Solution Design Team"
      tasks:
        - name: "solution_designer"
          agent_class: "c4h_agents.agents.solution_designer.SolutionDesigner"
          requires_approval: true
          max_retries: 1
      routing:
        rules:
          - condition: "all_success"
            next_team: "coder"
          - condition: "any_failure"
            next_team: "fallback"
        default: "coder"  # Default next team
    
    # Coder team - implements code changes
    coder:
      name: "Coder Team"
      tasks:
        - name: "coder"
          agent_class: "c4h_agents.agents.coder.Coder"
          requires_approval: true
          max_retries: 1
      routing:
        rules:
          - condition: "all_success"
            next_team: null  # End workflow on success
        default: null  # End workflow by default
    
    # Fallback team - handles failures with simplified approach
    fallback:
      name: "Fallback Team"
      tasks:
        - name: "fallback_coder"
          agent_class: "c4h_agents.agents.coder.Coder"
          config:
            temperature: 0  # Lower temperature for more conservative changes
      routing:
        default: null  # End workflow after fallback

# Runtime configuration for workflow and lineage
runtime:
  # Workflow storage configuration
  workflow:
    storage:
      enabled: true
      root_dir: "workspaces/workflows"
      format: "yymmdd_hhmm_{workflow_id}"
      retention:
        max_runs: 10
        max_days: 30
      error_handling:
        ignore_storage_errors: true
        log_level: "ERROR"
  # Lineage tracking configuration
  lineage:
    enabled: true
    namespace: "c4h_agents"
    separate_input_output: true
    backend:
      type: "file"  # File-based storage is more reliable for initial testing
      path: "workspaces/lineage"  # Use explicit relative path
    error_handling:
      ignore_failures: true  # Don't let lineage errors affect workflow
      log_level: "ERROR"
    context:
      include_metrics: true
      include_token_usage: true
      record_timestamps: true
    retry:
      enabled: true
      max_attempts: 3
      initial_delay: 1
      max_delay: 30
      backoff_factor: 2
      retry_on:
        - "overloaded_error"
        - "rate_limit_error"
        - "timeout_error"

# Backup settings
backup:
  enabled: true
  path: "workspaces/backups"  # Default backup path

logging:
  level: "INFO"
  format: "structured"
  agent_level: "INFO"
  providers:
    anthropic:
      level: "debug"
    openai:
      level: "debug"
  truncate:
    prefix_length: 30
    suffix_length: 30